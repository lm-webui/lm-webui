# --- Stage 1: Build Frontend (Static Assets) ---
FROM node:24-alpine AS frontend-builder

WORKDIR /frontend
COPY frontend/package*.json ./
# Install dependencies for build
RUN npm ci
COPY frontend/ ./ 
# Output: /frontend/dist
RUN npm run build

# --- Stage 2: Runtime Environment (CUDA Optimized) ---
# Using Ubuntu 24.04 as base to provide Python 3.12 by default
FROM nvidia/cuda:12.4.1-runtime-ubuntu24.04

WORKDIR /backend

# 1. System Dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip python3-venv \
    libgomp1 libstdc++6 curl git build-essential \
    && rm -rf /var/lib/apt/lists/*

# 2. Python Environment
ENV PYTHONUNBUFFERED=1 \
    PIP_ROOT_USER_ACTION=ignore \
    PIP_NO_CACHE_DIR=1

# Upgrade pip
RUN python3 -m pip install --upgrade pip setuptools wheel

# 3. Install PyTorch with CUDA support (CUDA 12.4)
# Using index-url to force CUDA version
RUN python3 -m pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124

# 4. Install llama-cpp-python with CUDA support
# We must set CMAKE_ARGS to enable CUBLAS/CUDA support if compiling from source,
# but using the wheel is preferred if available.
# Since we want production stability, we try the wheel first.
RUN python3 -m pip install llama-cpp-python==0.3.16 \
    --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124

# 5. Install Python dependencies
COPY backend/requirements.txt ./requirements.txt
RUN python3 -m pip install -r requirements.txt

# 6. Copy Application Code
COPY backend/ ./

# 7. Copy Frontend Assets from Builder Stage
COPY --from=frontend-builder /frontend/dist ./frontend/dist

# 8. Create Persistent Directories
RUN mkdir -p /backend/data/qdrant_db \
             /backend/media/uploads \
             /backend/data/memory \
             /backend/data/models \
             /backend/app/persistent_build

# 9. Environment
ENV PYTHONPATH=/backend
ENV CONFIG_PATH=/backend/config.yaml
ENV FORCED_BACKEND=cuda

EXPOSE 8000

COPY docker-entrypoint.sh /
RUN chmod +x /docker-entrypoint.sh

ENTRYPOINT ["/docker-entrypoint.sh"]

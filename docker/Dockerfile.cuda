# CUDA variant - optimized for NVIDIA GPUs (RTX/GTX/Ada Lovelace)
# Requires NVIDIA Container Toolkit
FROM nvidia/cuda:12.4.1-runtime-ubuntu22.04

WORKDIR /backend

# 1. Install system dependencies + Python
RUN apt-get update && apt-get install -y \
    python3.11 python3-pip python3-venv \
    libgomp1 libstdc++6 curl git \
    && rm -rf /var/lib/apt/lists/*

# 2. Python Environment
ENV PYTHONUNBUFFERED=1 PIP_ROOT_USER_ACTION=ignore

RUN pip3 install --upgrade pip

# 3. Install PyTorch with CUDA 12.1
RUN pip install --no-cache-dir \
    torch torchvision --index-url https://download.pytorch.org/whl/cu121

# 4. Install llama-cpp-python with CUDA support
RUN pip install --no-cache-dir llama-cpp-python[cuda]==0.3.16

# 5. Install Python dependencies
COPY backend/requirements.txt /tmp/requirements.txt
RUN pip install --no-cache-dir -r /tmp/requirements.txt

# 6. Copy Application Code
COPY backend/ ./backend/

# 7. Create Persistent Directories
RUN mkdir -p /backend/data/qdrant_db \
             /backend/media/uploads \
             /backend/data/memory \
             /backend/data/models \
             /backend/app/persistent_build

# 8. Environment
ENV PYTHONPATH=/backend
ENV CONFIG_PATH=/backend/config.yaml
ENV FORCED_BACKEND=cuda

EXPOSE 8000

COPY docker-entrypoint.sh /
RUN chmod +x /docker-entrypoint.sh
ENTRYPOINT ["/docker-entrypoint.sh"]

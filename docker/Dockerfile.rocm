# ROCm variant - optimized for AMD GPUs (RX 7000+, CDNA architectures)
# Requires ROCm 5.6+
FROM rocm/ubuntu:22.04

WORKDIR /backend

# 1. Install system dependencies + Python
RUN apt-get update && apt-get install -y \
    python3.11 python3-pip python3-venv \
    libgomp1 libstdc++6 curl git \
    && rm -rf /var/lib/apt/lists/*

# 2. Python Environment
ENV PYTHONUNBUFFERED=1 PIP_ROOT_USER_ACTION=ignore

RUN pip3 install --upgrade pip

# 3. Install PyTorch with ROCm support
RUN pip install --no-cache-dir \
    torch torchvision --index-url https://download.pytorch.org/whl/rocm5.7

# 4. Install llama-cpp-python with ROCm support
# Note: ROCm support requires building from source or using pre-built wheels
RUN pip install --no-cache-dir \
    llama-cpp-python==0.3.16 \
    --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/rocm

# 5. Install Python dependencies
COPY backend/requirements.txt /tmp/requirements.txt
RUN pip install --no-cache-dir -r /tmp/requirements.txt

# 6. Copy Application Code
COPY backend/ ./backend/

# 7. Create Persistent Directories
RUN mkdir -p /backend/data/qdrant_db \
             /backend/media/uploads \
             /backend/data/memory \
             /backend/data/models \
             /backend/app/persistent_build

# 8. Environment
ENV PYTHONPATH=/backend
ENV CONFIG_PATH=/backend/config.yaml
ENV FORCED_BACKEND=rocm
ENV HIP_VISIBLE_DEVICES=0

EXPOSE 8000

COPY docker-entrypoint.sh /
RUN chmod +x /docker-entrypoint.sh
ENTRYPOINT ["/docker-entrypoint.sh"]

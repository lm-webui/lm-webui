# ==============================================================================
# SYCL / INTEL ARC DOCKERFILE
# ==============================================================================
# Optimized for Intel Arc GPUs (Discrete) using Intel oneAPI Base Toolkit
# ==============================================================================

# --- Stage 1: Build Frontend (Static Assets) ---
FROM node:24-alpine AS frontend-builder

WORKDIR /frontend
COPY frontend/package*.json ./
# Install dependencies for build
RUN npm ci
COPY frontend/ ./ 
# Output: /frontend/dist
RUN npm run build

# --- Stage 2: Runtime Environment (SYCL Optimized) ---
FROM intel/oneapi-basekit:2025.3.1-0-devel-ubuntu22.04

WORKDIR /backend

# 1. System Dependencies
# Install Python 3.12 explicitly as Ubuntu 22.04 defaults to 3.10
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=Asia/Singapore

RUN apt-get update && apt-get install -y --no-install-recommends \
    tzdata \
    software-properties-common && \
    add-apt-repository ppa:deadsnakes/ppa -y && \
    apt-get update && \
    apt-get install -y --no-install-recommends \
    python3.12 python3.12-dev python3.12-venv \
    libgomp1 libstdc++6 curl git build-essential \
    && ln -fs /usr/share/zoneinfo/$TZ /etc/localtime \
    && dpkg-reconfigure --frontend noninteractive tzdata \
    && rm -rf /var/lib/apt/lists/*

# 2. Python Environment
ENV PYTHONUNBUFFERED=1 \
    PIP_ROOT_USER_ACTION=ignore \
    PIP_NO_CACHE_DIR=1 \
    PIP_BREAK_SYSTEM_PACKAGES=1

# Use Python 3.12 for all subsequent steps
RUN ln -sf /usr/bin/python3.12 /usr/bin/python3 && \
    curl -sS https://bootstrap.pypa.io/get-pip.py | python3.12

# 3. Install PyTorch with SYCL/XPU support (Intel Extension for PyTorch)
# Using the stable XPU release wheel
RUN python3 -m pip install \
    torch torchvision --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/

# 4. Build llama-cpp-python from source with SYCL support
# We must compile it against the oneAPI headers provided by the base image
ENV CMAKE_ARGS="-DGGML_SYCL=ON -DCMAKE_C_COMPILER=icx -DCMAKE_CXX_COMPILER=icpx"
ENV FORCE_CMAKE=1

RUN python3 -m pip install llama-cpp-python==0.3.16

# 5. Install Python dependencies
COPY backend/requirements.txt ./requirements.txt
RUN python3 -m pip install -r requirements.txt

# 6. Copy Application Code
COPY backend/ ./

# 7. Copy Frontend Assets from Builder Stage
COPY --from=frontend-builder /frontend/dist ./frontend/dist

# 8. Create Persistent Directories
RUN mkdir -p /backend/data/sql_db \
             /backend/data/qdrant_db \
             /backend/data/memory \
             /backend/media/generated \
             /backend/media/uploads \
             /backend/models \
             /backend/rag/embed \
             /backend/rag/ocr \
             /backend/rag/rerank \
             /backend/rag/vision \
             /backend/.secrets \
             /backend/app/persistent_build

# 9. Hardware Acceleration Variables
ENV PYTHONPATH=/backend
ENV CONFIG_PATH=/backend/config.yaml
ENV FORCED_BACKEND=sycl
# Enable persistent cache for faster startup on subsequent runs
ENV SYCL_CACHE_PERSISTENT=1
# Use Level Zero as the default backend for Arc GPUs
ENV ONEAPI_DEVICE_SELECTOR=level_zero:gpu

EXPOSE 8000

COPY docker-entrypoint.sh /
RUN chmod +x /docker-entrypoint.sh
ENTRYPOINT ["/docker-entrypoint.sh"]

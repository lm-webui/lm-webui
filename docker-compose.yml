services:
  lm-webui:
    build:
      context: .
      # Tip: Use a build argument to switch between Dockerfile.cuda and Dockerfile.rocm
      dockerfile: ${DOCKERFILE_PATH:-docker/Dockerfile.cuda}
    image: lm-webui:production
    container_name: lm-webui-v1
    ports:
      - "7070:8000"

    # 1. Hardware Access (The Modern Way)
    deploy:
      resources:
        reservations:
          devices:
            - driver: ${GPU_DRIVER:-nvidia} # Swaps between nvidia/amd
              count: all
              capabilities: [gpu]

    # 2. Add these for AMD/Intel Compatibility
    # These nodes are ignored by NVIDIA but REQUIRED for ROCm/SYCL
    devices:
      - "/dev/kfd:/dev/kfd"
      - "/dev/dri:/dev/dri"

    # 3. Increase Shared Memory
    # Crucial for ROCm and Intel Arc to prevent "Bus Error" crashes
    shm_size: "8gb"

    volumes:
      - app_data:/backend/data
      - app_media:/backend/media
      - ./backend/config.yaml:/backend/config.yaml
      - build_cache:/backend/app/persistent_build
      - ./backend/models:/backend/data/models
      - ./backend/.secrets:/backend/.secrets:ro # Added :ro for security

    environment:
      - HF_HOME=/backend/data/models
      - CONFIG_PATH=/backend/config.yaml
      - FORCED_BACKEND=${FORCED_BACKEND:-auto}
      # Hardware specific tuning
      - HSA_OVERRIDE_GFX_VERSION=${HSA_OVERRIDE_GFX_VERSION:-}
      - ONEAPI_DEVICE_SELECTOR=level_zero:gpu

    restart: unless-stopped

volumes:
  app_data:
  app_media:
  build_cache:

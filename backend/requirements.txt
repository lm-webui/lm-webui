# Core dependencies
fastapi
uvicorn[standard]
pydantic
requests>=2.32.0
psutil
aiohttp>=3.11.0
aiofiles
websockets
sse-starlette
passlib[bcrypt]
pyjwt
cryptography>=44.0.0
python-jose[cryptography]
python-dotenv
python-multipart
tiktoken
huggingface-hub
urllib3>=2.0.0
ddgs

# LLM Provider APIs
openai
anthropic
xai-sdk
google-genai==1.62.0

# RAG System Dependencies
qdrant-client==1.16.2
easyocr==1.7.2
transformers[torch]==4.49.0
accelerate>=0.30.0
sentence-transformers>=5.2.2
rank-bm25
pdfplumber
python-docx
python-pptx
pylightxl
xlrd
markdown
beautifulsoup4>=4.12.0

# Image & OCR
Pillow>=11.0.0
torchvision>=0.20.0


# --- CPU / DEFAULT ---
torch>=2.1.0; platform_system != "Linux" and platform_system != "Darwin"
llama-cpp-python==0.3.16

# --- APPLE SILICON (M1/M2/M3/M4) ---
torch>=2.1.0; platform_system == "Darwin"
llama-cpp-python==0.3.16; platform_system == "Darwin"

# --- LINUX CPU (Docker/Container) ---
--extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu
llama-cpp-python==0.3.16; platform_system == "Linux"

# --- NVIDIA CUDA (RTX 3000/4000/5000) ---
--extra-index-url https://download.pytorch.org/whl/cu128
torch>=2.1.0; platform_system == "Linux" or platform_system == "Windows"
llama-cpp-python[cuda]==0.3.16; platform_system == "Linux" or platform_system == "Windows"

# --- AMD ROCm (RDNA3/RDNA4) ---
--extra-index-url https://download.pytorch.org/whl/rocm7.2
torch>=2.1.0; platform_system == "Linux" or platform_system == "Windows"
llama-cpp-python==0.3.16; platform_system == "Linux" or platform_system == "Windows"

# --- INTEL ARC / SYCL (Arc A/B) ---
--extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/
torch>=2.1.0; platform_system == "Linux" and "xpu" in sys_platform
